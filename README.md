# Text-Related-Papers
This repository contains a paper collection of the latest text-related papers from top conferences.

## Table of Contents
- [Text Recognition](#Text-Recognition)
- [Text to Image (Diffusion Models)](#text_to_image)
- [Multi-modal Large Language Model (MLLM)](#MLLM)
- [Text Detection](#text_detection)
##

### Text Recognition
+ [PosFormer: Recognizing Complex Handwritten Mathematical Expression with Position Forest Transformer](https://arxiv.org/pdf/2407.07764) (ECCV2024)
  [![Code](https://img.shields.io/badge/GitHub-available-brightgreen?style=flat&logo=github&logoColor=black)](https://github.com/SJTU-DeepVisionLab/PosFormer)
+ [Self-supervised Character-to-Character Distillation for Text Recognition](https://arxiv.org/pdf/2211.00288.pdf) (ICCV 2023)
  [code](https://github.com/TongkunGuan/CCD)
+ [MRN: Multiplexed Routing Network for Incremental Multilingual Text Recognition](https://arxiv.org/abs/2305.14758) (ICCV 2023)
  [code](https://github.com/simplify23/MRN)
+ [Revisiting Scene Text Recognition: A Data Perspective](https://arxiv.org/abs/2307.08723) (ICCV 2023)
  [code](https://github.com/Mountchicken/Union14M)
+ [Self-Supervised Implicit Glyph Attention for Text Recognition](https://openaccess.thecvf.com/content/CVPR2023/html/Guan_Self-Supervised_Implicit_Glyph_Attention_for_Text_Recognition_CVPR_2023_paper.html) (CVPR 2023)
  [code](https://github.com/TongkunGuan/SIGA)
+ [Relational Contrastive Learning for Scene Text Recognition](https://arxiv.org/pdf/2308.00508.pdf) (ACMMM 2023)
  [code](https://github.com/ThunderVVV/RCLSTR)
+ [TPS++: Attention-Enhanced Thin-Plate Spline for Scene Text Recognition](https://arxiv.org/abs/2305.05322) (IJCAI 2023)
  [code](https://github.com/simplify23/TPS_PP)
+ [Linguistic More: Taking a Further Step toward Efficient and Accurate Scene Text Recognition](https://arxiv.org/pdf/2305.05140.pdf) (IJCAI 2023)
  [code](https://github.com/CyrilSterling/LPV)
+ [Reading and Writing: Discriminative and Generative Modeling for Self-Supervised Text Recognition](https://dl.acm.org/doi/abs/10.1145/3503161.3547784) (ACMMM 2022)  
  [code](https://github.com/ayumiymk/DiG)
+ [Chinese Character Recognition with Augmented Character Profile Matching](https://dl.acm.org/doi/abs/10.1145/3503161.3547827) (ACMMM 2022)  
  [code](https://github.com/FudanVI/FudanOCR/tree/main/character-profile-matching)
+ [Scene Text Recognition with Permuted Autoregressive Sequence Models](https://link.springer.com/chapter/10.1007/978-3-031-19815-1_11) (ECCV 2022)  
  [code](https://github.com/baudm/parseq)
+ [Task Grouping for Multilingual Text Recognition (Workshops)](https://link.springer.com/chapter/10.1007/978-3-031-25069-9_20) (ECCV 2022 Workshops)  
  [code](https://github.com)
+ [Multi-modal Text Recognition Networks: Interactive Enhancements Between Visual and Semantic Features](https://link.springer.com/chapter/10.1007/978-3-031-19815-1_26) (ECCV 2022)  
  [code](https://github.com/wp03052/MATRN)
+ [On Calibration of Scene-Text Recognition Models (Workshops)](https://link.springer.com/chapter/10.1007/978-3-031-25069-9_18) (ECCV 2022 Workshops)  
  [code](https://github.com)
+ [Pure Transformer with Integrated Experts for Scene Text Recognition](https://link.springer.com/chapter/10.1007/978-3-031-19815-1_28) (ECCV 2022)  
  [code](https://github.com)
+ [Optimal Boxes: Boosting End-to-End Scene Text Recognition by Adjusting Annotated Bounding Boxes via Reinforcement Learning](https://link.springer.com/chapter/10.1007/978-3-031-19815-1_14) (ECCV 2022)  
  [code](https://github.com)
+ [Multi-granularity Prediction for Scene Text Recognition](https://link.springer.com/chapter/10.1007/978-3-031-19815-1_20) (ECCV 2022)  
  [code](https://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/OCR/MGP-STR)
+ [Toward Understanding WordArt: Corner-Guided Transformer for Scene Text Recognition](https://link.springer.com/chapter/10.1007/978-3-031-19815-1_18) (ECCV 2022)  
  [code](https://github.com/xdxie/WordArt)
+ [Background-Insensitive Scene Text Recognition with Text Semantic Segmentation](https://link.springer.com/chapter/10.1007/978-3-031-19806-9_10) (ECCV 2022)  
  [code](https://github.com)
+ [SGBANet: Semantic GAN and Balanced Attention Network for Arbitrarily Oriented Scene Text Recognition](https://link.springer.com/chapter/10.1007/978-3-031-19815-1_27) (ECCV 2022)  
  [code](https://github.com)
+ [Levenshtein OCR](https://link.springer.com/chapter/10.1007/978-3-031-19815-1_19) (ECCV 2022)  
  [code](https://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/OCR/LevOCR)
+ [SVTR: Scene Text Recognition with a Single Visual Model](https://arxiv.org/abs/2205.00159) (IJCAI 2022)  
  [code](https://github.com/PaddlePaddle/PaddleOCR)
+ [Open-Set Text Recognition via Character-Context Decoupling](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Open-Set_Text_Recognition_via_Character-Context_Decoupling_CVPR_2022_paper.pdf) (CVPR 2022)  
  [code](https://github.com/lancercat/VSDF)
+ [Knowledge Mining with Scene Text for Fine-Grained Recognition](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Knowledge_Mining_With_Scene_Text_for_Fine-Grained_Recognition_CVPR_2022_paper.pdf) (CVPR 2022)  
  [code](https://github.com/MCLAB-OCR/KnowledgeMiningWithSceneText)
+ [Visual Semantics Allow for Textual Reasoning Better in Scene Text Recognition](https://ojs.aaai.org/index.php/AAAI/article/view/19971) (AAAI 2022)  
  [code](https://github.com/adeline-cs/GTR)
+ [Perceiving Stroke-Semantic Context: Hierarchical Contrastive Learning for Robust Scene Text Recognition](https://ojs.aaai.org/index.php/AAAI/article/view/20062) (AAAI 2022)  
  [code](https://github.com)
+ [Context-Based Contrastive Learning for Scene Text Recognition](https://ojs.aaai.org/index.php/AAAI/article/view/20245) (AAAI 2022)  
  [code](https://github.com)
+ [Sequence-to-Sequence Contrastive Learning for Text Recognition](https://openaccess.thecvf.com/content/CVPR2021/papers/Aberdam_Sequence-to-Sequence_Contrastive_Learning_for_Text_Recognition_CVPR_2021_paper.pdf) (CVPR 2021)  
  [code](https://github.com)
+ [What if We Only Use Real Datasets for Scene Text Recognition? Toward Scene Text Recognition With Fewer Labels](https://openaccess.thecvf.com/content/CVPR2021/papers/Baek_What_if_We_Only_Use_Real_Datasets_for_Scene_Text_CVPR_2021_paper.pdf) (CVPR 2021)  
  [code](https://github.com/ku21fan/STR-Fewer-Labels)
+ [MetaHTR: Towards Writer-Adaptive Handwritten Text Recognition](https://openaccess.thecvf.com/content/CVPR2021/papers/Bhunia_MetaHTR_Towards_Writer-Adaptive_Handwritten_Text_Recognition_CVPR_2021_paper.pdf) (CVPR 2021)  
  [code](https://github.com/tobiasvanderwerff/MetaHTR)
+ [Read Like Humans: Autonomous, Bidirectional and Iterative Language Modeling for Scene Text Recognition](https://openaccess.thecvf.com/content/CVPR2021/papers/Fang_Read_Like_Humans_Autonomous_Bidirectional_and_Iterative_Language_Modeling_for_CVPR_2021_paper.pdf) (CVPR 2021)  
  [code](https://github.com/FangShancheng/ABINet)
+ [Dictionary-Guided Scene Text Recognition](https://openaccess.thecvf.com/content/CVPR2021/papers/Nguyen_Dictionary-Guided_Scene_Text_Recognition_CVPR_2021_paper.pdf) (CVPR 2021)  
  [code](https://github.com/VinAIResearch/dict-guided)
+ [Primitive Representation Learning for Scene Text Recognition](https://openaccess.thecvf.com/content/CVPR2021/papers/Yan_Primitive_Representation_Learning_for_Scene_Text_Recognition_CVPR_2021_paper.pdf) (CVPR 2021)  
  [code](https://github.com/RuijieJ/pren)





### ICCV 2023
- **Self-supervised Character-to-Character Distillation for Text Recognition**
[`paper`](https://arxiv.org/pdf/2211.00288.pdf)
[`code`](https://github.com/TongkunGuan/CCD)
- **MRN: Multiplexed Routing Network for Incremental Multilingual Text Recognition**
[`paper`](https://arxiv.org/abs/2305.14758)
[`code`](https://github.com/simplify23/MRN)
- **Revisiting Scene Text Recognition: A Data Perspective**
[`paper`](https://arxiv.org/abs/2307.08723)
[`code`](https://github.com/Mountchicken/Union14M)

### CVPR2023
- **Self-Supervised Implicit Glyph Attention for Text Recognition**
[`paper`](https://openaccess.thecvf.com/content/CVPR2023/html/Guan_Self-Supervised_Implicit_Glyph_Attention_for_Text_Recognition_CVPR_2023_paper.html)
[`code`](https://github.com/TongkunGuan/SIGA)

### ACMMM2023
- **Relational Contrastive Learning for Scene Text Recognition**
[`paper`](https://arxiv.org/pdf/2308.00508.pdf)
[`code`](https://github.com/ThunderVVV/RCLSTR)

### IJCAI2023
- **TPS++: Attention-Enhanced Thin-Plate Spline for Scene Text Recognition**
[`paper`](https://arxiv.org/abs/2305.05322)
[`code`](https://github.com/simplify23/TPS_PP)
- **Linguistic More: Taking a Further Step toward Efficient and Accurate Scene Text Recognition**
[`paper`](https://arxiv.org/pdf/2305.05140.pdf)
[`code`](https://github.com/CyrilSterling/LPV)
- **Orientation-Independent Chinese Text Recognition in Scene Images**
[`paper`]()
[`code`]()

### ACMMM2022
- **Reading and Writing: Discriminative and Generative Modeling for Self-Supervised Text Recognition**
[`paper`](https://dl.acm.org/doi/abs/10.1145/3503161.3547784)
[`code`](https://github.com/ayumiymk/DiG)
- **Chinese Character Recognition with Augmented Character Profile Matching**
[`paper`](https://dl.acm.org/doi/abs/10.1145/3503161.3547827)
[`code`](https://github.com/FudanVI/FudanOCR/tree/main/character-profile-matching)

### ECCV2022
- **Scene Text Recognition with Permuted Autoregressive Sequence Models**
[`paper`](https://link.springer.com/chapter/10.1007/978-3-031-19815-1_11)
[`code`](https://github.com/baudm/parseq)
- **Task Grouping for Multilingual Text Recognition (Workshops)**
[`paper`](https://link.springer.com/chapter/10.1007/978-3-031-25069-9_20)
[`code`]()
- **Multi-modal Text Recognition Networks: Interactive Enhancements Between Visual and Semantic Features**
[`paper`](https://link.springer.com/chapter/10.1007/978-3-031-19815-1_26)
[`code`](https://github.com/wp03052/MATRN)
- **On Calibration of Scene-Text Recognition Models (Workshops)**
[`paper`](https://link.springer.com/chapter/10.1007/978-3-031-25069-9_18)
[`code`]()
- **Pure Transformer with Integrated Experts for Scene Text Recognition**
[`paper`](https://link.springer.com/chapter/10.1007/978-3-031-19815-1_28)
[`code`]()
- **Optimal Boxes: Boosting End-to-End Scene Text Recognition by Adjusting Annotated Bounding Boxes via Reinforcement Learning**
[`paper`](https://link.springer.com/chapter/10.1007/978-3-031-19815-1_14)
[`code`]()
- **Multi-granularity Prediction for Scene Text Recognition**
[`paper`](https://link.springer.com/chapter/10.1007/978-3-031-19815-1_20)
[`code`](https://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/OCR/MGP-STR)
- **Toward Understanding WordArt: Corner-Guided Transformer for Scene Text Recognition**
[`paper`](https://link.springer.com/chapter/10.1007/978-3-031-19815-1_18)
[`code`](https://github.com/xdxie/WordArt)
- **Background-Insensitive Scene Text Recognition with Text Semantic Segmentation**
[`paper`](https://link.springer.com/chapter/10.1007/978-3-031-19806-9_10)
[`code`]()
- **SGBANet: Semantic GAN and Balanced Attention Network for Arbitrarily Oriented Scene Text Recognition**
[`paper`](https://link.springer.com/chapter/10.1007/978-3-031-19815-1_27)
[`code`]()
- **Levenshtein OCR**
[`paper`](https://link.springer.com/chapter/10.1007/978-3-031-19815-1_19)
[`code`](https://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/OCR/LevOCR)

### IJCAI2022
- **SVTR: Scene Text Recognition with a Single Visual Model**
[`paper`](https://arxiv.org/abs/2205.00159)
[`code`](https://github.com/PaddlePaddle/PaddleOCR)

### CVPR2022
- **Open-Set Text Recognition via Character-Context Decoupling**
[`paper`](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Open-Set_Text_Recognition_via_Character-Context_Decoupling_CVPR_2022_paper.pdf)
[`code`](https://github.com/lancercat/VSDF)

- **Knowledge Mining with Scene Text for Fine-Grained Recognition**
[`paper`](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Knowledge_Mining_With_Scene_Text_for_Fine-Grained_Recognition_CVPR_2022_paper.pdf)
[`code`](https://github.com/MCLAB-OCR/KnowledgeMiningWithSceneText)

### AAAI2022
- **Visual Semantics Allow for Textual Reasoning Better in Scene Text Recognition**
[`paper`](https://ojs.aaai.org/index.php/AAAI/article/view/19971)
[`code`](https://github.com/adeline-cs/GTR)
- **Perceiving Stroke-Semantic Context: Hierarchical Contrastive Learning for Robust Scene Text Recognition**
[`paper`](https://ojs.aaai.org/index.php/AAAI/article/view/20062)
[`code`]()
- **Context-Based Contrastive Learning for Scene Text Recognition**
[`paper`](https://ojs.aaai.org/index.php/AAAI/article/view/20245)
[`code`]()

### CVPR2021
- **Sequence-to-Sequence Contrastive Learning for Text Recognition**
[`paper`](https://openaccess.thecvf.com/content/CVPR2021/papers/Aberdam_Sequence-to-Sequence_Contrastive_Learning_for_Text_Recognition_CVPR_2021_paper.pdf)
[`code`]()
- **What if We Only Use Real Datasets for Scene Text Recognition? Toward Scene Text Recognition With Fewer Labels**
[`paper`](https://openaccess.thecvf.com/content/CVPR2021/papers/Baek_What_if_We_Only_Use_Real_Datasets_for_Scene_Text_CVPR_2021_paper.pdf)
[`code`](https://github.com/ku21fan/STR-Fewer-Labels)
- **MetaHTR: Towards Writer-Adaptive Handwritten Text Recognition**
[`paper`](https://openaccess.thecvf.com/content/CVPR2021/papers/Bhunia_MetaHTR_Towards_Writer-Adaptive_Handwritten_Text_Recognition_CVPR_2021_paper.pdf)
[`code`](https://github.com/tobiasvanderwerff/MetaHTR) 
- **Read Like Humans: Autonomous, Bidirectional and Iterative Language Modeling for Scene Text Recognition**
[`paper`](https://openaccess.thecvf.com/content/CVPR2021/papers/Fang_Read_Like_Humans_Autonomous_Bidirectional_and_Iterative_Language_Modeling_for_CVPR_2021_paper.pdf)
[`code`](https://github.com/FangShancheng/ABINet)
- **Dictionary-Guided Scene Text Recognition**
[`paper`](https://openaccess.thecvf.com/content/CVPR2021/papers/Nguyen_Dictionary-Guided_Scene_Text_Recognition_CVPR_2021_paper.pdf)
[`code`](https://github.com/VinAIResearch/dict-guided)
- **Primitive Representation Learning for Scene Text Recognition**
[`paper`](https://openaccess.thecvf.com/content/CVPR2021/papers/Yan_Primitive_Representation_Learning_for_Scene_Text_Recognition_CVPR_2021_paper.pdf)
[`code`](https://github.com/RuijieJ/pren)
</details>

<details>
<summary><strong>Text to Image (Diffusion Models)</strong></summary>
  
### ECCV2024
- **Glyph-ByT5: A Customized Text Encoder for Accurate Visual Text Rendering**
  [`paper`](https://arxiv.org/pdf/2403.09622)
  [`code`](https://glyph-byt5.github.io/)
  
  **Glyph-ByT5-v2: A Strong Aesthetic Baseline for Accurate Multilingual Visual Text Rendering**
  [`paper`](https://arxiv.org/pdf/2406.10208)
  [`code`](https://glyph-byt5-v2.github.io/)

### ICLR2024
- **ANYTEXT: MULTILINGUAL VISUAL TEXT GENERATION AND EDITING**
  [`paper`](https://arxiv.org/pdf/2311.03054)
  [`code`](https://github.com/tyxsspa/AnyText)

### ACL 2023
- **Character-Aware Models Improve Visual Text Rendering**
  [`paper`](https://arxiv.org/pdf/2212.10562)
  [`code`]()


### NeurIPS 2023
- **TextDiffuser: Diffusion Models as Text Painters**
  [`paper`](https://arxiv.org/pdf/2305.10855)
  [`code`](https://aka.ms/textdiffuser)
- **GlyphControl: Glyph Conditional Control for Visual Text Generation**
  [`paper`](https://arxiv.org/pdf/2305.18259)
  [`code`](https://github.com/AIGText/GlyphControl-release)


### CVPR 2024
- **Layout-Agnostic Scene Text Image Synthesis with Diffusion Models**
  [`paper`](https://openaccess.thecvf.com/content/CVPR2024/papers/Zhangli_Layout-Agnostic_Scene_Text_Image_Synthesis_with_Diffusion_Models_CVPR_2024_paper.pdf)
- **CustomText: Customized Textual Image Generation using Diffusion Models**
  [`paper`](https://arxiv.org/pdf/2405.12531)

### Arxiv
- **TextDiffuser-2: Unleashing the Power of Language Models for Text Rendering**
  [`paper`](https://arxiv.org/pdf/2311.16465)
  [`code`](https://aka.ms/textdiffuser-2)
- **Refining Text-to-Image Generation: Towards Accurate Training-Free Glyph-Enhanced Image Generation**
  [`paper`](https://arxiv.org/pdf/2403.16422)
- **Typographic Text Generation with Off-the-Shelf Diffusion Model**
  [`paper`](https://arxiv.org/pdf/2402.14314)
- **High Fidelity Scene Text Synthesis**
  [`paper`](https://arxiv.org/pdf/2405.14701)
  [`code`](https://github.com/CodeGoat24/DreamText)
- **UDiffText: A Unified Framework for High-quality Text Synthesis in Arbitrary Images via Character-aware Diffusion Models**
  [`paper`](https://arxiv.org/abs/2312.04884)
  [`code`](https://github.com/ZYM-PKU/UDiffText)
- **GlyphDraw2: Automatic Generation of Complex Glyph Posters with Diffusion Models and Large Language Models**
  [`paper`](https://arxiv.org/pdf/2407.02252)
  [`code`](https://github.com/OPPO-Mente-Lab/GlyphDraw2)
- **ARTIST: Improving the Generation of Text-rich Images by Disentanglement**
  [`paper`](https://arxiv.org/pdf/2406.12044)



</details>

<details>
<summary><strong>Multi-modal Large Language Model (MLLM)</strong></summary>

### CVPR24
- **InternVL: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks**
[`paper`](https://openaccess.thecvf.com/content/CVPR2024/papers/Chen_InternVL_Scaling_up_Vision_Foundation_Models_and_Aligning_for_Generic_CVPR_2024_paper.pdf)
[`code`](https://github.com/OpenGVLab/InternVL)
- **TRINS: Towards Multimodal Language Models that Can Read**
  [`paper`](https://openaccess.thecvf.com/content/CVPR2024/papers/Zhang_TRINS_Towards_Multimodal_Language_Models_that_Can_Read_CVPR_2024_paper.pdf)

### EMNLP23
- **UReader: Universal OCR-free Visually-situated Language Understanding with Multimodal Large Language Model**
  [`paper`](https://arxiv.org/pdf/2310.05126)
  [`code`](https://github.com/LukeForeverYoung/UReader)

### Arxiv
- **On Pre-training of Multimodal Language Models Customized for Chart Understanding**
  [`paper`](https://arxiv.org/pdf/2407.14506)
  
- **LLaVA-Read: Enhancing Reading Ability of Multimodal Language Models**
  [`paper`](https://arxiv.org/pdf/2407.19185)
  
- **Multimodal Table Understanding**
  [`paper`](https://arxiv.org/pdf/2406.08100)
  [`code`](https://github.com/SpursGoZmy/Table-LLaVA)

- **Token-level Correlation-guided Compression for Efficient Multimodal Document Understanding**
  [`paper`](https://arxiv.org/pdf/2407.14439) 4gpu
  [`code`](https://github.com/JiuTian-VL/TokenCorrCompressor)
   
- **LayTextLLM: A Bounding Box is Worth One Token - Interleaving Layout and Text in a Large Language Model for Document Understanding**
  [`paper`](https://arxiv.org/pdf/2407.01976) 8gpu
  [`code`](https://github.com/LayTextLLM/LayTextLLM)

- **MoAI: Mixture of All Intelligence for Large Language and Vision Models**
[`paper`](https://arxiv.org/abs/2403.07508)
[`code`](https://github.com/ByungKwanLee/MoAI)

- **Leveraging Visual Tokens for Extended Text Contexts in Multi-Modal Learning**
[`paper`](https://arxiv.org/abs/2406.02547)
[`code`](https://fingerrec.github.io/visincontext/)

- **TextMonkey: An OCR-Free Large Multimodal Model for Understanding Document**
[`paper`](https://arxiv.org/abs/2403.04473)
[`code`](https://github.com/Yuliang-Liu/Monkey)

- **DocPedia: Unleashing the Power of Large Multimodal Model in the Frequency Domain for Versatile Document Understanding**
[`paper`](https://arxiv.org/pdf/2311.11810)

- **Vary: Scaling up the Vision Vocabulary for Large Vision-Language Models**
[`paper`](https://arxiv.org/pdf/2312.06109)
[`code`](https://varybase.github.io/)

- **Fox: Focus Anywhere for Fine-grained Multi-page Document Understanding**
[`paper`](https://arxiv.org/abs/2405.14295)
[`code`](https://github.com/Ucas-HaoranWei/Fox)

- **TextHawk: Exploring Efficient Fine-Grained Perception of Multimodal Large Language Models**
[`paper`](https://arxiv.org/abs/2404.09204)
[`code`](https://github.com/yuyq96/TextHawk)

- **mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding**
[`paper`](https://arxiv.org/abs/2403.12895)
[`code`](https://github.com/X-PLUG/mPLUG-DocOwl/tree/main/DocOwl1.5)
</details>

<details>
<summary><strong>Text Detection</strong></summary>
  
### ECCV 2024
  - **Bridging Synthetic and Real Worlds for Pre-training Scene Text Detector**
  [`paper`](https://arxiv.org/pdf/2312.05286)
  [`code`](https://github.com/SJTU-DeepVisionLab/FreeReal)
  
### AAAI 2024
- **LORE: Logical Location Regression Network for Table Structure Recognition**
  [`paper`](https://arxiv.org/pdf/2303.03730.pdf)
  [`code`](https://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/DocumentUnderstanding/LORE-TSR)
- **LRANet: Towards Accurate and Efficient Scene Text Detection with Low-Rank Approximation Network**
[`paper`](https://arxiv.org/abs/2306.15142)
[`code`](https://github.com/ychensu/LRANet)
- **CPN: Complementary Proposal Network for Unconstrained Text Detection**
[`paper`](https://arxiv.org/pdf/2402.11540.pdf)

</details>

